{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dotsnangles/from-keras-to-pytorch-and-more/blob/main/stylegan2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9qbVplkZYjp"
      },
      "source": [
        "# Training StyleGAN2 in Google CoLab\n",
        "\n",
        "GANs can be trained with either Google Colab Free or Pro.  The Pro version is reccomended due to better GPU instances, longer runtimes, and timeouts.  Make sure that you are running this notebook with a GPU runtime.\n",
        "\n",
        "Your training data and trained neural networks will be stored to GDRIVE.  For GANs, I lay out my GDRIVE like this:\n",
        "\n",
        "* ./data/gan/images - RAW images I wish to train on.\n",
        "* ./data/gan/datasets - Actual training datasets that I convert from the raw images.\n",
        "* ./data/gan/experiments - The output from StyleGAN2, my image previews and saved network snapshots.\n",
        "\n",
        "The drive is mounted to the following location.\n",
        "\n",
        "```\n",
        "/content/drive/MyDrive/data\n",
        "```\n",
        "\n",
        "\n",
        "# What Sort of GPU do you Have?\n",
        "\n",
        "The type of GPU assigned to you by Colab will greatly affect your training time. Some sample times that I achieved with Colab are given here.  I've found that Colab Pro generally starts you with a V100, however, if you run scripts non-stop for 24hrs straight for a few days in a row, you will generally be throttled back to a P100.\n",
        "\n",
        "* 1024x1024 - V100 - 566 sec/tick (CoLab Pro)\n",
        "* 1024x1024 - P100 - 1819 sec/tick (CoLab Pro)\n",
        "* 1024x1024 - T4 - 2188 sec/tick (CoLab Free)\n",
        "\n",
        "If you use Google CoLab Pro, generally, it will not disconnect before 24 hours, even if you (but not your script) are inactive.  Free CoLab WILL disconnect a perfectly good running script if you do not interact for a few hours.  The following describes how to circumvent this issue.\n",
        "\n",
        "* [How to prevent Google Colab from disconnecting?](https://stackoverflow.com/questions/57113226/how-to-prevent-google-colab-from-disconnecting)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPrGcTX8c7E-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7052311d-9b54-4641-cbb1-5da408e6c9ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec 29 02:42:45 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P0    30W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzWrFN_tGV-Y"
      },
      "source": [
        "# Set Up New Environment\n",
        "\n",
        "You will likely need to train for >24 hours.  Colab will disconnect you.  You must be prepared to restart training when this eventually happens.  Training is divided into ticks, every so many ticks (50 by default) your neural network is evaluated and a snapshot is saved.  When CoLab shuts down, all training after the last snapshot is lost. It might seem desirable to snapshot after each tick; however, this snapshotting process itself takes nearly an hour.  It is important to learn an optimal snapshot size for your resolution and training data.\n",
        "\n",
        "We will mount GDRIVE so that your snapshots are saved there.  You must also place your training images in GDRIVE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uxs1j1bk_fwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "583200bb-3002-4103-9be6-08b79f81d7b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X41Ll0WtYqB0"
      },
      "source": [
        "You must also install NVIDIA StyleGAN2 ADA PyTorch.  We also need to downgrade PyTorch to a version that supports StyleGAN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uNqsi6VWAlWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e4e8bb-6d66-4799-fb0c-25c8a9e558dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 804.1 MB 6.2 kB/s \n",
            "\u001b[K     |████████████████████████████████| 17.4 MB 283 kB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 58.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.5 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.8.1 which is incompatible.\n",
            "torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hCloning into 'stylegan2-ada-pytorch'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Total 128 (delta 0), reused 0 (delta 0), pack-reused 128\u001b[K\n",
            "Receiving objects: 100% (128/128), 1.12 MiB | 35.87 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n",
            "Cloning into 'pyimgdata'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 31 (delta 13), reused 19 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (31/31), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch==1.8.1 torchvision==0.9.1 flickrapi ninja\n",
        "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git\n",
        "!git clone https://github.com/jeffheaton/pyimgdata.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 폴더를 생성하고 크롤링을 시작합니다."
      ],
      "metadata": {
        "id": "ymAilYhWl_px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/data/gan/images\n",
        "!mkdir -p /content/drive/MyDrive/data/gan/datasets\n",
        "!mkdir -p /content/drive/MyDrive/data/gan/experiments "
      ],
      "metadata": {
        "id": "5BzTjZ2Lh3AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  flickr 계정을 생성하고 api key/secret을 부여받아야 합니다.\n",
        "- /content/pyimgdata/config_flickr.ini 설정이 필요합니다."
      ],
      "metadata": {
        "id": "ZuXoGNnRmLX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/pyimgdata\n",
        "!python flickr-download.py\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9droAEVBi0Ur",
        "outputId": "828ddae8-a590-4b41-c474-9d2154358ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pyimgdata\n",
            "2022-12-29 01:48:57,140 - root - INFO : Line 166 - Starting...\n",
            "2022-12-29 01:49:57,247 - root - INFO : Line 147 - Update for 1: images=163; errors=0; cached=59\n",
            "2022-12-29 01:50:57,162 - root - INFO : Line 147 - Update for 2: images=322; errors=0; cached=93\n",
            "2022-12-29 01:51:57,346 - root - INFO : Line 147 - Update for 3: images=493; errors=0; cached=95\n",
            "2022-12-29 01:52:57,225 - root - INFO : Line 147 - Update for 4: images=654; errors=0; cached=147\n",
            "2022-12-29 01:53:57,470 - root - INFO : Line 147 - Update for 5: images=819; errors=0; cached=168\n",
            "2022-12-29 01:54:57,493 - root - INFO : Line 147 - Update for 6: images=984; errors=0; cached=179\n",
            "2022-12-29 01:55:57,414 - root - INFO : Line 147 - Update for 7: images=1,135; errors=0; cached=272\n",
            "2022-12-29 01:56:57,443 - root - INFO : Line 147 - Update for 8: images=1,298; errors=0; cached=272\n",
            "2022-12-29 01:57:57,494 - root - INFO : Line 147 - Update for 9: images=1,466; errors=0; cached=272\n",
            "2022-12-29 01:58:57,179 - root - INFO : Line 147 - Update for 10: images=1,619; errors=0; cached=313\n",
            "2022-12-29 01:59:57,311 - root - INFO : Line 147 - Update for 11: images=1,775; errors=0; cached=358\n",
            "2022-12-29 02:00:57,288 - root - INFO : Line 147 - Update for 12: images=1,930; errors=0; cached=401\n",
            "2022-12-29 02:01:57,321 - root - INFO : Line 147 - Update for 13: images=2,092; errors=0; cached=443\n",
            "2022-12-29 02:02:57,409 - root - INFO : Line 147 - Update for 14: images=2,250; errors=0; cached=506\n",
            "2022-12-29 02:03:57,384 - root - INFO : Line 147 - Update for 15: images=2,410; errors=0; cached=517\n",
            "2022-12-29 02:04:58,631 - root - INFO : Line 147 - Update for 16: images=2,561; errors=0; cached=560\n",
            "2022-12-29 02:05:57,755 - root - INFO : Line 147 - Update for 17: images=2,713; errors=0; cached=588\n",
            "2022-12-29 02:06:57,479 - root - INFO : Line 147 - Update for 18: images=2,866; errors=0; cached=609\n",
            "2022-12-29 02:07:57,165 - root - INFO : Line 147 - Update for 19: images=3,018; errors=0; cached=657\n",
            "2022-12-29 02:08:57,158 - root - INFO : Line 147 - Update for 20: images=3,070; errors=0; cached=1,380\n",
            "2022-12-29 02:09:57,180 - root - INFO : Line 147 - Update for 21: images=3,083; errors=0; cached=2,379\n",
            "2022-12-29 02:10:57,169 - root - INFO : Line 147 - Update for 22: images=3,090; errors=0; cached=3,420\n",
            "2022-12-29 02:11:57,170 - root - INFO : Line 147 - Update for 23: images=3,095; errors=0; cached=4,499\n",
            "2022-12-29 02:12:57,176 - root - INFO : Line 147 - Update for 24: images=3,095; errors=0; cached=5,569\n",
            "2022-12-29 02:13:57,145 - root - INFO : Line 147 - Update for 25: images=3,098; errors=0; cached=6,646\n",
            "2022-12-29 02:14:57,192 - root - INFO : Line 147 - Update for 26: images=3,098; errors=0; cached=7,749\n",
            "2022-12-29 02:15:57,158 - root - INFO : Line 147 - Update for 27: images=3,098; errors=0; cached=8,810\n",
            "2022-12-29 02:16:57,171 - root - INFO : Line 147 - Update for 28: images=3,098; errors=0; cached=9,889\n",
            "2022-12-29 02:17:57,169 - root - INFO : Line 147 - Update for 29: images=3,098; errors=0; cached=10,972\n",
            "2022-12-29 02:18:57,149 - root - INFO : Line 147 - Update for 30: images=3,098; errors=0; cached=12,030\n",
            "2022-12-29 02:19:57,190 - root - INFO : Line 147 - Update for 31: images=3,103; errors=0; cached=13,065\n",
            "2022-12-29 02:20:57,159 - root - INFO : Line 147 - Update for 32: images=3,104; errors=0; cached=14,130\n",
            "2022-12-29 02:21:57,163 - root - INFO : Line 147 - Update for 33: images=3,104; errors=0; cached=14,988\n",
            "2022-12-29 02:22:57,183 - root - INFO : Line 147 - Update for 34: images=3,104; errors=0; cached=16,108\n",
            "2022-12-29 02:23:57,290 - root - INFO : Line 147 - Update for 35: images=3,105; errors=0; cached=17,171\n",
            "2022-12-29 02:24:57,161 - root - INFO : Line 147 - Update for 36: images=3,106; errors=0; cached=18,270\n",
            "2022-12-29 02:25:57,164 - root - INFO : Line 147 - Update for 37: images=3,106; errors=0; cached=19,292\n",
            "2022-12-29 02:26:57,196 - root - INFO : Line 147 - Update for 38: images=3,106; errors=0; cached=20,031\n",
            "2022-12-29 02:27:57,173 - root - INFO : Line 147 - Update for 39: images=3,106; errors=0; cached=21,162\n",
            "2022-12-29 02:28:57,169 - root - INFO : Line 147 - Update for 40: images=3,107; errors=0; cached=22,264\n",
            "2022-12-29 02:29:57,159 - root - INFO : Line 147 - Update for 41: images=3,108; errors=0; cached=23,370\n",
            "2022-12-29 02:30:57,174 - root - INFO : Line 147 - Update for 42: images=3,108; errors=0; cached=24,466\n",
            "2022-12-29 02:31:57,160 - root - INFO : Line 147 - Update for 43: images=3,111; errors=0; cached=25,536\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 377, in _make_request\n",
            "TypeError: getresponse() got an unexpected keyword argument 'buffering'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"flickr-download.py\", line 195, in <module>\n",
            "    task.run()\n",
            "  File \"flickr-download.py\", line 178, in run\n",
            "    for photo in photos:\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/flickrapi/core.py\", line 688, in data_walker\n",
            "    rsp = method(page=page, **params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/flickrapi/call_builder.py\", line 38, in __call__\n",
            "    return self.flickrapi_object.do_flickr_call(self.method_name, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/flickrapi/core.py\", line 334, in do_flickr_call\n",
            "    return self._wrap_in_parser(self._flickr_call,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/flickrapi/core.py\", line 399, in _wrap_in_parser\n",
            "    data = wrapped_method(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/flickrapi/core.py\", line 377, in _flickr_call\n",
            "    reply = self.flickr_oauth.do_request(self.REST_URL, kwargs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/flickrapi/auth.py\", line 250, in do_request\n",
            "    req = self.session.post(url,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/requests/sessions.py\", line 578, in post\n",
            "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/requests/sessions.py\", line 530, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/requests/sessions.py\", line 643, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/requests/adapters.py\", line 439, in send\n",
            "    resp = conn.urlopen(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 597, in urlopen\n",
            "    httplib_response = self._make_request(conn, method, url,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 380, in _make_request\n",
            "    httplib_response = conn.getresponse()\n",
            "  File \"/usr/lib/python3.8/http/client.py\", line 1348, in getresponse\n",
            "    response.begin()\n",
            "  File \"/usr/lib/python3.8/http/client.py\", line 316, in begin\n",
            "    version, status, reason = self._read_status()\n",
            "  File \"/usr/lib/python3.8/http/client.py\", line 277, in _read_status\n",
            "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
            "  File \"/usr/lib/python3.8/socket.py\", line 669, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "  File \"/usr/lib/python3.8/ssl.py\", line 1241, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "  File \"/usr/lib/python3.8/ssl.py\", line 1099, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmSOo3HvGwgV"
      },
      "source": [
        "# Clean Up your Images\n",
        "\n",
        "It is important that all images have the same dimensions and color depth.  This code can identify images that have issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLKBUUfXHJ0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c90958dee76d4836a1e8864e679d11e7",
            "745f1ce7b77844a2ac9413ae85b29303",
            "5ef5bdb82a264a2b9bc5812f9d9a2cca",
            "db7699ef256943c4bd083903c48209e3",
            "a45d22c6faf8403482ad0640f56da4d6",
            "7f47b62f449b41f68bcf50e343a14b9f",
            "aed784ecc9e446978006c3d2bdf13490",
            "c4199336a08b491c98fd464921eca0b7",
            "f943227bc3884fa083770d06cefb150c",
            "3fefa591557d4129a91358363fea9044",
            "d347badffe884c29996438e67f63f720"
          ]
        },
        "outputId": "522e910c-583e-4e03-fd73-d88bbf8f1c95"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3220 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c90958dee76d4836a1e8864e679d11e7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "IMAGE_PATH = '/content/drive/MyDrive/data/gan/images'\n",
        "files = [f for f in listdir(IMAGE_PATH) if isfile(join(IMAGE_PATH, f))]\n",
        "\n",
        "base_size = None\n",
        "for file in tqdm(files):\n",
        "  file2 = os.path.join(IMAGE_PATH,file)\n",
        "  img = Image.open(file2)\n",
        "  sz = img.size\n",
        "  if base_size and sz!=base_size:\n",
        "    print(f\"Inconsistant size: {file2}\")\n",
        "  elif img.mode!='RGB':\n",
        "    print(f\"Inconsistant color format: {file2}\")\n",
        "  else:\n",
        "    base_size = sz\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXAgXh8uGo13"
      },
      "source": [
        "# Convert Your Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYP2NlwHA6r9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89b2ba68-7395-44c2-dfd3-ff5b8c118ff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 3220/3220 [01:09<00:00, 46.39it/s]\n"
          ]
        }
      ],
      "source": [
        "!python /content/stylegan2-ada-pytorch/dataset_tool.py --source /content/drive/MyDrive/data/gan/images --dest /content/drive/MyDrive/data/gan/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otsNELpn8_2D"
      },
      "source": [
        "The following command can be used to clear out the newly created dataset.  If something goes wrong and you need to clean up your images and rerun the above command, you should delete your partially created dataset directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctdqmU96BhB3"
      },
      "outputs": [],
      "source": [
        "#!rm -R /content/drive/MyDrive/data/gan/dataset/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5No-bokaG5Ed"
      },
      "source": [
        "# Perform Initial Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzAdHMp7KLzz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb9d2071-e538-40a6-f43a-da351de65fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/data/gan/dataset\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 3220,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 256\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 2,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 16384,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 0.8192\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"ema_rampup\": 0.05,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"run_dir\": \"/content/drive/MyDrive/data/gan/experiments/00002-dataset-auto1\"\n",
            "}\n",
            "\n",
            "Output directory:   /content/drive/MyDrive/data/gan/experiments/00002-dataset-auto1\n",
            "Training data:      /content/drive/MyDrive/data/gan/dataset\n",
            "Training duration:  25000 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   3220\n",
            "Image resolution:   256\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "\n",
            "Num images:  3220\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Generator             Parameters  Buffers  Output shape         Datatype\n",
            "---                   ---         ---      ---                  ---     \n",
            "mapping.fc0           262656      -        [16, 512]            float32 \n",
            "mapping.fc1           262656      -        [16, 512]            float32 \n",
            "mapping               -           512      [16, 14, 512]        float32 \n",
            "synthesis.b4.conv1    2622465     32       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4.torgb    264195      -        [16, 3, 4, 4]        float32 \n",
            "synthesis.b4:0        8192        16       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4:1        -           -        [16, 512, 4, 4]      float32 \n",
            "synthesis.b8.conv0    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.conv1    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.torgb    264195      -        [16, 3, 8, 8]        float32 \n",
            "synthesis.b8:0        -           16       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8:1        -           -        [16, 512, 8, 8]      float32 \n",
            "synthesis.b16.conv0   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.conv1   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.torgb   264195      -        [16, 3, 16, 16]      float32 \n",
            "synthesis.b16:0       -           16       [16, 512, 16, 16]    float32 \n",
            "synthesis.b16:1       -           -        [16, 512, 16, 16]    float32 \n",
            "synthesis.b32.conv0   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.conv1   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.torgb   264195      -        [16, 3, 32, 32]      float16 \n",
            "synthesis.b32:0       -           16       [16, 512, 32, 32]    float16 \n",
            "synthesis.b32:1       -           -        [16, 512, 32, 32]    float32 \n",
            "synthesis.b64.conv0   1442561     4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.conv1   721409      4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.torgb   132099      -        [16, 3, 64, 64]      float16 \n",
            "synthesis.b64:0       -           16       [16, 256, 64, 64]    float16 \n",
            "synthesis.b64:1       -           -        [16, 256, 64, 64]    float32 \n",
            "synthesis.b128.conv0  426369      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.conv1  213249      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.torgb  66051       -        [16, 3, 128, 128]    float16 \n",
            "synthesis.b128:0      -           16       [16, 128, 128, 128]  float16 \n",
            "synthesis.b128:1      -           -        [16, 128, 128, 128]  float32 \n",
            "synthesis.b256.conv0  139457      65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.conv1  69761       65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.torgb  33027       -        [16, 3, 256, 256]    float16 \n",
            "synthesis.b256:0      -           16       [16, 64, 256, 256]   float16 \n",
            "synthesis.b256:1      -           -        [16, 64, 256, 256]   float32 \n",
            "---                   ---         ---      ---                  ---     \n",
            "Total                 23191522    175568   -                    -       \n",
            "\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   256         16       [16, 64, 256, 256]   float16 \n",
            "b256.skip      8192        16       [16, 128, 128, 128]  float16 \n",
            "b256.conv0     36928       16       [16, 64, 256, 256]   float16 \n",
            "b256.conv1     73856       16       [16, 128, 128, 128]  float16 \n",
            "b256           -           16       [16, 128, 128, 128]  float16 \n",
            "b128.skip      32768       16       [16, 256, 64, 64]    float16 \n",
            "b128.conv0     147584      16       [16, 128, 128, 128]  float16 \n",
            "b128.conv1     295168      16       [16, 256, 64, 64]    float16 \n",
            "b128           -           16       [16, 256, 64, 64]    float16 \n",
            "b64.skip       131072      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      590080      16       [16, 256, 64, 64]    float16 \n",
            "b64.conv1      1180160     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          24001089    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 52s          sec/tick 9.5     sec/kimg 593.14  maintenance 42.2   cpumem 4.86   gpumem 11.17  augment 0.000\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 297.57207812341494}, \"metric\": \"fid50k_full\", \"total_time\": 640.7252945899963, \"total_time_str\": \"10m 41s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1672284338.921163}\n",
            "tick 1     kimg 4.0      time 16m 31s      sec/tick 282.7   sec/kimg 70.67   maintenance 657.1  cpumem 5.31   gpumem 9.39   augment 0.006\n",
            "tick 2     kimg 8.0      time 21m 15s      sec/tick 283.6   sec/kimg 70.91   maintenance 0.1    cpumem 5.31   gpumem 4.87   augment 0.013\n",
            "tick 3     kimg 12.0     time 25m 59s      sec/tick 283.2   sec/kimg 70.81   maintenance 0.1    cpumem 5.31   gpumem 4.87   augment 0.019\n",
            "tick 4     kimg 16.0     time 30m 44s      sec/tick 285.2   sec/kimg 71.31   maintenance 0.1    cpumem 5.31   gpumem 4.88   augment 0.025\n",
            "tick 5     kimg 20.0     time 35m 30s      sec/tick 285.5   sec/kimg 71.37   maintenance 0.1    cpumem 5.31   gpumem 4.88   augment 0.031\n",
            "tick 6     kimg 24.0     time 40m 15s      sec/tick 285.6   sec/kimg 71.41   maintenance 0.2    cpumem 5.31   gpumem 4.93   augment 0.037\n",
            "tick 7     kimg 28.0     time 45m 02s      sec/tick 286.3   sec/kimg 71.57   maintenance 0.1    cpumem 5.31   gpumem 4.89   augment 0.040\n",
            "tick 8     kimg 32.0     time 49m 49s      sec/tick 286.9   sec/kimg 71.72   maintenance 0.1    cpumem 5.32   gpumem 4.88   augment 0.046\n",
            "tick 9     kimg 36.0     time 54m 35s      sec/tick 286.0   sec/kimg 71.50   maintenance 0.2    cpumem 5.32   gpumem 4.91   augment 0.051\n",
            "tick 10    kimg 40.0     time 59m 22s      sec/tick 286.8   sec/kimg 71.71   maintenance 0.1    cpumem 5.32   gpumem 4.94   augment 0.056\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 300.61630142982955}, \"metric\": \"fid50k_full\", \"total_time\": 635.3812792301178, \"total_time_str\": \"10m 35s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000040.pkl\", \"timestamp\": 1672287841.337559}\n",
            "tick 11    kimg 44.0     time 1h 14m 58s   sec/tick 286.3   sec/kimg 71.59   maintenance 649.2  cpumem 5.82   gpumem 4.90   augment 0.058\n",
            "tick 12    kimg 48.0     time 1h 19m 45s   sec/tick 286.9   sec/kimg 71.73   maintenance 0.1    cpumem 5.82   gpumem 4.89   augment 0.060\n",
            "tick 13    kimg 52.0     time 1h 24m 31s   sec/tick 286.5   sec/kimg 71.62   maintenance 0.1    cpumem 5.82   gpumem 4.89   augment 0.062\n",
            "tick 14    kimg 56.0     time 1h 29m 18s   sec/tick 286.4   sec/kimg 71.61   maintenance 0.1    cpumem 5.82   gpumem 4.91   augment 0.065\n",
            "tick 15    kimg 60.0     time 1h 34m 05s   sec/tick 287.2   sec/kimg 71.79   maintenance 0.1    cpumem 5.82   gpumem 4.91   augment 0.067\n",
            "tick 16    kimg 64.0     time 1h 38m 53s   sec/tick 287.6   sec/kimg 71.90   maintenance 0.1    cpumem 5.82   gpumem 4.93   augment 0.065\n",
            "tick 17    kimg 68.0     time 1h 43m 40s   sec/tick 286.6   sec/kimg 71.64   maintenance 0.2    cpumem 5.82   gpumem 4.93   augment 0.063\n",
            "tick 18    kimg 72.0     time 1h 48m 27s   sec/tick 287.5   sec/kimg 71.89   maintenance 0.1    cpumem 5.82   gpumem 4.91   augment 0.061\n",
            "tick 19    kimg 76.0     time 1h 53m 14s   sec/tick 286.7   sec/kimg 71.67   maintenance 0.1    cpumem 5.82   gpumem 4.88   augment 0.059\n",
            "tick 20    kimg 80.0     time 1h 58m 02s   sec/tick 287.7   sec/kimg 71.92   maintenance 0.1    cpumem 5.82   gpumem 4.94   augment 0.057\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 274.77153949147447}, \"metric\": \"fid50k_full\", \"total_time\": 639.1291687488556, \"total_time_str\": \"10m 39s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000080.pkl\", \"timestamp\": 1672291368.0023217}\n",
            "tick 21    kimg 84.0     time 2h 13m 46s   sec/tick 287.7   sec/kimg 71.93   maintenance 656.0  cpumem 5.95   gpumem 4.92   augment 0.056\n",
            "tick 22    kimg 88.0     time 2h 18m 33s   sec/tick 287.6   sec/kimg 71.90   maintenance 0.1    cpumem 5.94   gpumem 4.92   augment 0.056\n",
            "tick 23    kimg 92.0     time 2h 23m 20s   sec/tick 287.0   sec/kimg 71.75   maintenance 0.1    cpumem 5.94   gpumem 4.91   augment 0.054\n",
            "tick 24    kimg 96.0     time 2h 28m 08s   sec/tick 287.7   sec/kimg 71.93   maintenance 0.1    cpumem 5.93   gpumem 4.90   augment 0.054\n",
            "tick 25    kimg 100.0    time 2h 32m 55s   sec/tick 286.6   sec/kimg 71.66   maintenance 0.2    cpumem 5.93   gpumem 4.93   augment 0.054\n",
            "tick 26    kimg 104.0    time 2h 37m 44s   sec/tick 288.5   sec/kimg 72.13   maintenance 0.2    cpumem 5.92   gpumem 4.93   augment 0.054\n",
            "tick 27    kimg 108.0    time 2h 42m 31s   sec/tick 287.2   sec/kimg 71.81   maintenance 0.1    cpumem 5.86   gpumem 4.93   augment 0.055\n",
            "tick 28    kimg 112.0    time 2h 47m 20s   sec/tick 288.5   sec/kimg 72.13   maintenance 0.1    cpumem 5.85   gpumem 4.92   augment 0.055\n",
            "tick 29    kimg 116.0    time 2h 52m 08s   sec/tick 287.7   sec/kimg 71.92   maintenance 0.1    cpumem 5.85   gpumem 4.91   augment 0.055\n",
            "tick 30    kimg 120.0    time 2h 56m 55s   sec/tick 287.5   sec/kimg 71.87   maintenance 0.1    cpumem 5.85   gpumem 4.89   augment 0.056\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 230.4979681324117}, \"metric\": \"fid50k_full\", \"total_time\": 638.4833495616913, \"total_time_str\": \"10m 38s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000120.pkl\", \"timestamp\": 1672294902.0556717}\n",
            "tick 31    kimg 124.0    time 3h 12m 40s   sec/tick 288.5   sec/kimg 72.12   maintenance 656.6  cpumem 5.49   gpumem 4.90   augment 0.058\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Modify these to suit your needs\n",
        "EXPERIMENTS = \"/content/drive/MyDrive/data/gan/experiments\"\n",
        "DATA = \"/content/drive/MyDrive/data/gan/dataset\"\n",
        "SNAP = 10\n",
        "WORKERS = 2\n",
        "\n",
        "# Build the command and run it\n",
        "cmd = f\"/usr/bin/python3 /content/stylegan2-ada-pytorch/train.py --snap {SNAP} --outdir {EXPERIMENTS} --data {DATA} --workers {WORKERS}\"\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS-oe6jMG_0A"
      },
      "source": [
        "# Resume Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvPZLsCUlzGn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fffcdd3-4e34-453d-8098-71c8ceedd10c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/data/gan/dataset\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 3220,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 256\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 2,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 16384,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 0.8192\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"ema_rampup\": null,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/data/gan/experiments/00008-dataset-auto1-resumecustom/network-snapshot-000120.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/data/gan/experiments/00010-dataset-auto1-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:   /content/drive/MyDrive/data/gan/experiments/00010-dataset-auto1-resumecustom\n",
            "Training data:      /content/drive/MyDrive/data/gan/dataset\n",
            "Training duration:  25000 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   3220\n",
            "Image resolution:   256\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "\n",
            "Num images:  3220\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"/content/drive/MyDrive/data/gan/experiments/00008-dataset-auto1-resumecustom/network-snapshot-000120.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Generator             Parameters  Buffers  Output shape         Datatype\n",
            "---                   ---         ---      ---                  ---     \n",
            "mapping.fc0           262656      -        [16, 512]            float32 \n",
            "mapping.fc1           262656      -        [16, 512]            float32 \n",
            "mapping               -           512      [16, 14, 512]        float32 \n",
            "synthesis.b4.conv1    2622465     32       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4.torgb    264195      -        [16, 3, 4, 4]        float32 \n",
            "synthesis.b4:0        8192        16       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4:1        -           -        [16, 512, 4, 4]      float32 \n",
            "synthesis.b8.conv0    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.conv1    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.torgb    264195      -        [16, 3, 8, 8]        float32 \n",
            "synthesis.b8:0        -           16       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8:1        -           -        [16, 512, 8, 8]      float32 \n",
            "synthesis.b16.conv0   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.conv1   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.torgb   264195      -        [16, 3, 16, 16]      float32 \n",
            "synthesis.b16:0       -           16       [16, 512, 16, 16]    float32 \n",
            "synthesis.b16:1       -           -        [16, 512, 16, 16]    float32 \n",
            "synthesis.b32.conv0   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.conv1   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.torgb   264195      -        [16, 3, 32, 32]      float16 \n",
            "synthesis.b32:0       -           16       [16, 512, 32, 32]    float16 \n",
            "synthesis.b32:1       -           -        [16, 512, 32, 32]    float32 \n",
            "synthesis.b64.conv0   1442561     4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.conv1   721409      4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.torgb   132099      -        [16, 3, 64, 64]      float16 \n",
            "synthesis.b64:0       -           16       [16, 256, 64, 64]    float16 \n",
            "synthesis.b64:1       -           -        [16, 256, 64, 64]    float32 \n",
            "synthesis.b128.conv0  426369      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.conv1  213249      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.torgb  66051       -        [16, 3, 128, 128]    float16 \n",
            "synthesis.b128:0      -           16       [16, 128, 128, 128]  float16 \n",
            "synthesis.b128:1      -           -        [16, 128, 128, 128]  float32 \n",
            "synthesis.b256.conv0  139457      65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.conv1  69761       65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.torgb  33027       -        [16, 3, 256, 256]    float16 \n",
            "synthesis.b256:0      -           16       [16, 64, 256, 256]   float16 \n",
            "synthesis.b256:1      -           -        [16, 64, 256, 256]   float32 \n",
            "---                   ---         ---      ---                  ---     \n",
            "Total                 23191522    175568   -                    -       \n",
            "\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   256         16       [16, 64, 256, 256]   float16 \n",
            "b256.skip      8192        16       [16, 128, 128, 128]  float16 \n",
            "b256.conv0     36928       16       [16, 64, 256, 256]   float16 \n",
            "b256.conv1     73856       16       [16, 128, 128, 128]  float16 \n",
            "b256           -           16       [16, 128, 128, 128]  float16 \n",
            "b128.skip      32768       16       [16, 256, 64, 64]    float16 \n",
            "b128.conv0     147584      16       [16, 128, 128, 128]  float16 \n",
            "b128.conv1     295168      16       [16, 256, 64, 64]    float16 \n",
            "b128           -           16       [16, 256, 64, 64]    float16 \n",
            "b64.skip       131072      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      590080      16       [16, 256, 64, 64]    float16 \n",
            "b64.conv1      1180160     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          24001089    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 57s          sec/tick 9.4     sec/kimg 586.39  maintenance 48.1   cpumem 5.27   gpumem 11.17  augment 0.000\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 50.881742740746006}, \"metric\": \"fid50k_full\", \"total_time\": 632.1434390544891, \"total_time_str\": \"10m 32s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1672376965.0810986}\n",
            "tick 1     kimg 4.0      time 16m 34s      sec/tick 285.4   sec/kimg 71.34   maintenance 650.8  cpumem 5.63   gpumem 9.39   augment 0.026\n",
            "tick 2     kimg 8.0      time 21m 20s      sec/tick 286.5   sec/kimg 71.62   maintenance 0.1    cpumem 5.63   gpumem 4.91   augment 0.053\n",
            "tick 3     kimg 12.0     time 26m 06s      sec/tick 285.7   sec/kimg 71.42   maintenance 0.1    cpumem 5.64   gpumem 4.91   augment 0.077\n",
            "tick 4     kimg 16.0     time 30m 53s      sec/tick 287.2   sec/kimg 71.79   maintenance 0.2    cpumem 5.64   gpumem 4.90   augment 0.104\n",
            "tick 5     kimg 20.0     time 35m 40s      sec/tick 286.7   sec/kimg 71.67   maintenance 0.1    cpumem 5.64   gpumem 4.96   augment 0.118\n",
            "tick 6     kimg 24.0     time 40m 27s      sec/tick 286.9   sec/kimg 71.73   maintenance 0.1    cpumem 5.64   gpumem 4.94   augment 0.129\n",
            "tick 7     kimg 28.0     time 45m 14s      sec/tick 286.9   sec/kimg 71.72   maintenance 0.1    cpumem 5.64   gpumem 4.97   augment 0.138\n",
            "tick 8     kimg 32.0     time 50m 02s      sec/tick 287.4   sec/kimg 71.84   maintenance 0.1    cpumem 5.64   gpumem 4.98   augment 0.153\n",
            "tick 9     kimg 36.0     time 54m 49s      sec/tick 286.9   sec/kimg 71.72   maintenance 0.2    cpumem 5.64   gpumem 4.91   augment 0.162\n",
            "tick 10    kimg 40.0     time 59m 37s      sec/tick 287.5   sec/kimg 71.89   maintenance 0.2    cpumem 5.64   gpumem 4.94   augment 0.166\n",
            "Evaluating metrics...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Modify these to suit your needs\n",
        "EXPERIMENTS = \"/content/drive/MyDrive/data/gan/experiments\"\n",
        "NETWORK = \"network-snapshot-000120.pkl\"\n",
        "RESUME = os.path.join(EXPERIMENTS, \"00008-dataset-auto1-resumecustom\", NETWORK)\n",
        "DATA = \"/content/drive/MyDrive/data/gan/dataset\"\n",
        "SNAP = 10\n",
        "WORKERS = 2\n",
        "\n",
        "# Build the command and run it\n",
        "cmd = f\"/usr/bin/python3 /content/stylegan2-ada-pytorch/train.py --snap {SNAP} --resume {RESUME} --outdir {EXPERIMENTS} --data {DATA} --workers {WORKERS}\"\n",
        "!{cmd}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c90958dee76d4836a1e8864e679d11e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_745f1ce7b77844a2ac9413ae85b29303",
              "IPY_MODEL_5ef5bdb82a264a2b9bc5812f9d9a2cca",
              "IPY_MODEL_db7699ef256943c4bd083903c48209e3"
            ],
            "layout": "IPY_MODEL_a45d22c6faf8403482ad0640f56da4d6"
          }
        },
        "745f1ce7b77844a2ac9413ae85b29303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f47b62f449b41f68bcf50e343a14b9f",
            "placeholder": "​",
            "style": "IPY_MODEL_aed784ecc9e446978006c3d2bdf13490",
            "value": "100%"
          }
        },
        "5ef5bdb82a264a2b9bc5812f9d9a2cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4199336a08b491c98fd464921eca0b7",
            "max": 3220,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f943227bc3884fa083770d06cefb150c",
            "value": 3220
          }
        },
        "db7699ef256943c4bd083903c48209e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fefa591557d4129a91358363fea9044",
            "placeholder": "​",
            "style": "IPY_MODEL_d347badffe884c29996438e67f63f720",
            "value": " 3220/3220 [00:08&lt;00:00, 538.47it/s]"
          }
        },
        "a45d22c6faf8403482ad0640f56da4d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f47b62f449b41f68bcf50e343a14b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed784ecc9e446978006c3d2bdf13490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4199336a08b491c98fd464921eca0b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f943227bc3884fa083770d06cefb150c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fefa591557d4129a91358363fea9044": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d347badffe884c29996438e67f63f720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}